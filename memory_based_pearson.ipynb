{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Based Collaborative Filtering (Item-Based Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_all = pd.read_csv(\"data/raw/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampling (df,item_nos=900,item_split=[0.75,0.25]):\n",
    "    \n",
    "    ##############################    Data Preprocessing from User Perspective   #########################\n",
    "    \n",
    "    #Frequency of movie rating by each user\n",
    "    user_rtgs_cnt = (df.groupby(['userId']).count()).iloc[:,0:1].reset_index().rename(columns={\"movieId\":\"rating_cnt\"})\n",
    "    print (\"Original number of users in dataset : \",len(user_rtgs_cnt))\n",
    "    \n",
    "    quantile_user=user_rtgs_cnt.quantile([0.1,.25,.75,0.9], axis = 0).drop([\"userId\"],axis=1)\n",
    "    print(\"Data distribution of frequency of movies rated by users : \\n \", quantile_user)\n",
    "    \n",
    "    #Removing the higher and lower 10% of the outliers.\n",
    "    user_rtgs_cnt=user_rtgs_cnt[np.logical_and((user_rtgs_cnt.rating_cnt>=quantile_user.iloc[0,0]),(user_rtgs_cnt.rating_cnt<=quantile_user.iloc[3,0]))]\n",
    "    print (\"Number of users in dataset post removal of bias based on user activity: \",len(user_rtgs_cnt))\n",
    "    \n",
    "    #These users are then removed from the dataset\n",
    "    df=df.merge(user_rtgs_cnt[['userId']],on=\"userId\", how=\"inner\")   \n",
    "    \n",
    "    ##############################  Data Preprocessing from Item Perspective   #########################\n",
    "    \n",
    "    #Count of Ratings per movie\n",
    "    item_count = (df[[\"movieId\",\"rating\"]].groupby(['movieId']).count()).reset_index().rename(columns={\"rating\":\"rating_per_item\"})\n",
    "    print(\"Original number of movies in dataset :\\n \",len(item_count))\n",
    "    \n",
    "    quantile_item=item_count.quantile([0.1,.25,.75,1], axis = 0).drop([\"movieId\"],axis=1)\n",
    "    print(\"Data distribution of frequency of ratings per movie : \\n \", quantile_item)\n",
    "    \n",
    "    #Removing all items which have less than 3 user counts i.e Q1 or based on a fixed number \n",
    "    #item_count=item_count[item_count.rating_per_item>=quantile_item.iloc[1,0]].reset_index(drop=True)\n",
    "    item_count=item_count[item_count.rating_per_item>=5].reset_index(drop=True)\n",
    "    item_count[\"item_subset\"]=np.where(item_count.rating_per_item < quantile_item.iloc[2,0],1,2)\n",
    "    print(\"Total number of movies in dataset post removal of low rated movies: \",len(item_count))\n",
    "    \n",
    "    \n",
    "    ##############################  Data Sampling   #########################\n",
    "    \n",
    "    sampled_ratings=pd.DataFrame()\n",
    "    j=len(item_split)-1\n",
    "    \n",
    "    for i in item_count.item_subset.unique():\n",
    "        sampled_ratings=sampled_ratings.append(item_count[item_count.item_subset==i].sample(n=int(item_split[j]*item_nos), random_state=10))\n",
    "        j=j-1\n",
    "        \n",
    "    sampled_ratings.reset_index(drop=True, inplace=True)   \n",
    "    print (\"Sum of all the ratings for the selected movies : \",sampled_ratings['rating_per_item'].sum())\n",
    "    \n",
    "    \n",
    "    #Select user rows for only those movies which have been sampled\n",
    "    df=df.merge(sampled_ratings[['movieId']],on=\"movieId\", how=\"inner\")\n",
    "    \n",
    "    #Since not all items are selected it may happen that we again get items with only user frequency.\n",
    "    #Removing single frequency users so as to reduce sparsity and enable item-item comparison between pairs\n",
    "    \n",
    "    user_rtgs_cnt_2=(df.groupby(['userId']).count()).iloc[:,0:1].reset_index().rename(columns={\"movieId\":\"user_freq\"})\n",
    "    df=df.merge(user_rtgs_cnt_2,on=\"userId\", how=\"inner\")\n",
    "    \n",
    "    #For any personalized recommendation to a user, we are setting a rule that user should have watched 5 movies before. \n",
    "    #Before that only popular recommendations to him\n",
    "    df=df[df.user_freq>5] \n",
    "    \n",
    "    \n",
    "    print(\"Number of rows in sampled dataset : \", len(df))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of users in dataset :  138493\n",
      "Data distribution of frequency of movies rated by users : \n",
      "        rating_cnt\n",
      "0.10        24.0\n",
      "0.25        35.0\n",
      "0.75       155.0\n",
      "0.90       334.0\n",
      "Number of users in dataset post removal of bias based on user activity:  111593\n",
      "Original number of movies in dataset :\n",
      "  18128\n",
      "Data distribution of frequency of ratings per movie : \n",
      "        rating_per_item\n",
      "0.10              1.0\n",
      "0.25              3.0\n",
      "0.75            150.0\n",
      "1.00          53083.0\n",
      "Total number of movies in dataset post removal of low rated movies:  12376\n",
      "Sum of all the ratings for the selected movies :  245692\n",
      "Number of rows in sampled dataset :  76894\n",
      "(76894, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2542</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4993</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6093</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  user_freq\n",
       "0       1      151     4.0          6\n",
       "1       1     2542     4.0          6\n",
       "2       1     2692     3.5          6\n",
       "3       1     4993     5.0          6\n",
       "4       1     6093     4.0          6"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings = ratings_all.sample(n=100000).reset_index(drop=True)\n",
    "ratings = data_sampling(ratings_all, item_split=[0.90, 0.10])\n",
    "ratings.drop(columns=['timestamp'], inplace=True)\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76894, 4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the ratings into training and test with 70-30%\n",
    "ratings_training = ratings.sample(frac=0.7)\n",
    "ratings_test = ratings.drop(ratings_training.index)\n",
    "ratings_training.reset_index(drop=True, inplace=True)\n",
    "ratings_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size (53826, 4)\n",
      "test data size (23068, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>91423</td>\n",
       "      <td>500</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3573</td>\n",
       "      <td>6709</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105275</td>\n",
       "      <td>280</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>82564</td>\n",
       "      <td>2542</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50071</td>\n",
       "      <td>33493</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  user_freq\n",
       "0   91423      500     3.5          6\n",
       "1    3573     6709     4.0          7\n",
       "2  105275      280     4.0          9\n",
       "3   82564     2542     4.0          7\n",
       "4   50071    33493     4.0          7"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"training data size\", ratings_training.shape)\n",
    "print(\"test data size\", ratings_test.shape)\n",
    "ratings_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an item-to-item matrix which will be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weight_matrix(ratings):\n",
    "    \n",
    "    # define weight matrix\n",
    "    w_matrix_columns = ['movie_1', 'movie_2', 'weight']\n",
    "    w_matrix = pd.DataFrame(columns = w_matrix_columns)\n",
    "\n",
    "    # calculate the similarity between pairs of movies\n",
    "    unique_movies = np.unique(ratings['movieId'])\n",
    "    print(\"Number of unique movies: \", len(unique_movies))\n",
    "    \n",
    "    i = 0\n",
    "    for movie_1 in unique_movies:\n",
    "        if i%10==0:\n",
    "            print(\"Processing \", i , \" movie out of \", len(unique_movies), \" movies\")\n",
    "\n",
    "        # extract all users who rated movie_1\n",
    "        user_data = ratings[ratings['movieId'] == movie_1]\n",
    "        unique_users = np.unique(user_data['userId'])\n",
    "\n",
    "        # record the ratings for users who rated both movie_1 and movie_2\n",
    "        record_row_columns = ['userId', 'movie_1', 'movie_2', 'rating_1', 'rating_2']\n",
    "        record_movie_1_2 = pd.DataFrame(columns=record_row_columns)\n",
    "        \n",
    "        # for each customer C who rated movie_1 record the her ratings for movie_2 \n",
    "        for c_userid in unique_users:\n",
    "            c_movie_1_rating = user_data[user_data['userId'] == c_userid]['rating'].iloc[0]\n",
    "            # all movies of user c excluding movie_1\n",
    "            c_user_data = ratings[(ratings['userId'] == c_userid) & (ratings['movieId'] != movie_1)]\n",
    "            c_unique_movies = np.unique(c_user_data['movieId'])\n",
    "\n",
    "            # Iterate through all movies rated by customer C as movie=2\n",
    "            for movie_2 in c_unique_movies:\n",
    "               # the customer's rating for movie_2\n",
    "                c_movie_2_rating = c_user_data[c_user_data['movieId'] == movie_2]['rating'].iloc[0]\n",
    "                record_row = pd.Series([c_userid, movie_1, movie_2, c_movie_1_rating, c_movie_2_rating], index=record_row_columns)\n",
    "                record_movie_1_2 = record_movie_1_2.append(record_row, ignore_index=True)\n",
    "        \n",
    "        # computing the similarity between movie_1 and the other recorded movies tagged as movie_2\n",
    "        unique_movie_2 = np.unique(record_movie_1_2['movie_2'])\n",
    "        # going through each movie 2\n",
    "        for movie_2 in unique_movie_2:\n",
    "            paired_movie_1_2 = record_movie_1_2[record_movie_1_2['movie_2'] == movie_2]\n",
    "            cosine_sim_numerator = (paired_movie_1_2['rating_1'] * paired_movie_1_2['rating_2']).sum()\n",
    "            cosine_sim_denominator = np.sqrt(np.square(paired_movie_1_2['rating_1']).sum()) * np.sqrt(np.square(paired_movie_1_2['rating_2']).sum())\n",
    "            cosine_sim_denominator = cosine_sim_denominator if cosine_sim_denominator != 0 else 1e-8\n",
    "            sim_value = cosine_sim_numerator / cosine_sim_denominator\n",
    "            w_matrix = w_matrix.append(pd.Series([movie_1, movie_2, sim_value], index=w_matrix_columns), ignore_index=True)\n",
    "            \n",
    "        i = i + 1\n",
    "    #return the computed weight matrix\n",
    "    return w_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique movies:  887\n",
      "Processing  0  movie out of  887  movies\n",
      "Processing  10  movie out of  887  movies\n",
      "Processing  20  movie out of  887  movies\n",
      "Processing  30  movie out of  887  movies\n",
      "Processing  40  movie out of  887  movies\n",
      "Processing  50  movie out of  887  movies\n",
      "Processing  60  movie out of  887  movies\n",
      "Processing  70  movie out of  887  movies\n",
      "Processing  80  movie out of  887  movies\n",
      "Processing  90  movie out of  887  movies\n",
      "Processing  100  movie out of  887  movies\n",
      "Processing  110  movie out of  887  movies\n",
      "Processing  120  movie out of  887  movies\n",
      "Processing  130  movie out of  887  movies\n",
      "Processing  140  movie out of  887  movies\n",
      "Processing  150  movie out of  887  movies\n",
      "Processing  160  movie out of  887  movies\n",
      "Processing  170  movie out of  887  movies\n",
      "Processing  180  movie out of  887  movies\n",
      "Processing  190  movie out of  887  movies\n",
      "Processing  200  movie out of  887  movies\n",
      "Processing  210  movie out of  887  movies\n",
      "Processing  220  movie out of  887  movies\n",
      "Processing  230  movie out of  887  movies\n",
      "Processing  240  movie out of  887  movies\n",
      "Processing  250  movie out of  887  movies\n",
      "Processing  260  movie out of  887  movies\n",
      "Processing  270  movie out of  887  movies\n",
      "Processing  280  movie out of  887  movies\n",
      "Processing  290  movie out of  887  movies\n",
      "Processing  300  movie out of  887  movies\n",
      "Processing  310  movie out of  887  movies\n",
      "Processing  320  movie out of  887  movies\n",
      "Processing  330  movie out of  887  movies\n",
      "Processing  340  movie out of  887  movies\n",
      "Processing  350  movie out of  887  movies\n",
      "Processing  360  movie out of  887  movies\n",
      "Processing  370  movie out of  887  movies\n",
      "Processing  380  movie out of  887  movies\n",
      "Processing  390  movie out of  887  movies\n",
      "Processing  400  movie out of  887  movies\n",
      "Processing  410  movie out of  887  movies\n",
      "Processing  420  movie out of  887  movies\n",
      "Processing  430  movie out of  887  movies\n",
      "Processing  440  movie out of  887  movies\n",
      "Processing  450  movie out of  887  movies\n",
      "Processing  460  movie out of  887  movies\n",
      "Processing  470  movie out of  887  movies\n",
      "Processing  480  movie out of  887  movies\n",
      "Processing  490  movie out of  887  movies\n",
      "Processing  500  movie out of  887  movies\n",
      "Processing  510  movie out of  887  movies\n",
      "Processing  520  movie out of  887  movies\n",
      "Processing  530  movie out of  887  movies\n",
      "Processing  540  movie out of  887  movies\n",
      "Processing  550  movie out of  887  movies\n",
      "Processing  560  movie out of  887  movies\n",
      "Processing  570  movie out of  887  movies\n",
      "Processing  580  movie out of  887  movies\n",
      "Processing  590  movie out of  887  movies\n",
      "Processing  600  movie out of  887  movies\n",
      "Processing  610  movie out of  887  movies\n",
      "Processing  620  movie out of  887  movies\n",
      "Processing  630  movie out of  887  movies\n",
      "Processing  640  movie out of  887  movies\n",
      "Processing  650  movie out of  887  movies\n",
      "Processing  660  movie out of  887  movies\n",
      "Processing  670  movie out of  887  movies\n",
      "Processing  680  movie out of  887  movies\n",
      "Processing  690  movie out of  887  movies\n",
      "Processing  700  movie out of  887  movies\n",
      "Processing  710  movie out of  887  movies\n",
      "Processing  720  movie out of  887  movies\n",
      "Processing  730  movie out of  887  movies\n",
      "Processing  740  movie out of  887  movies\n",
      "Processing  750  movie out of  887  movies\n",
      "Processing  760  movie out of  887  movies\n",
      "Processing  770  movie out of  887  movies\n",
      "Processing  780  movie out of  887  movies\n",
      "Processing  790  movie out of  887  movies\n",
      "Processing  800  movie out of  887  movies\n",
      "Processing  810  movie out of  887  movies\n",
      "Processing  820  movie out of  887  movies\n",
      "Processing  830  movie out of  887  movies\n",
      "Processing  840  movie out of  887  movies\n",
      "Processing  850  movie out of  887  movies\n",
      "Processing  860  movie out of  887  movies\n",
      "Processing  870  movie out of  887  movies\n",
      "Processing  880  movie out of  887  movies\n"
     ]
    }
   ],
   "source": [
    "w_matrix = build_weight_matrix(ratings_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6635"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(w_matrix['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the rating of unrated movies for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict a rating for a given user and given movie\n",
    "def predict(userId, movieId, w_matrix, ratings):\n",
    "    # predict the rating of the given movie by the given user\n",
    "    user_other_ratings = ratings[ratings['userId'] == userId]\n",
    "    user_unique_movies = np.unique(user_other_ratings['movieId'])\n",
    "    sum_weighted_other_ratings = 0\n",
    "    sum_weghts = 0\n",
    "    for movie_j in user_unique_movies:\n",
    "        # only calculate the weighted values when the weight between movie_1 and movie_2 exists in weight matrix\n",
    "        w_movie_1_2 = w_matrix[(w_matrix['movie_1'] == movieId) & (w_matrix['movie_2'] == movie_j)]\n",
    "        if len(w_movie_1_2) > 0:\n",
    "            user_rating_j = user_other_ratings[user_other_ratings['movieId']==movie_j]\n",
    "            sum_weighted_other_ratings += (user_rating_j['rating'].iloc[0] * w_movie_1_2['weight'].iloc[0])\n",
    "            sum_weghts += np.abs(w_movie_1_2['weight'].iloc[0])\n",
    "\n",
    "    # when sum_weights is 0 (in case there is no ratings from new users), use the mean ratings as 2.5\n",
    "    if sum_weghts == 0:\n",
    "        predicted_rating = 2.5\n",
    "    else:\n",
    "        predicted_rating = sum_weighted_other_ratings/sum_weghts\n",
    "    predicted_rating = round(predicted_rating, 3)\n",
    "    return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating: 3.835000\n"
     ]
    }
   ],
   "source": [
    "# predict a rating for a given user and given movie\n",
    "predicted_rating = predict(1, 151, w_matrix, ratings_training)\n",
    "print('The predicted rating: %f' % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the learned recommender system on test data by converting the ratings to negative and positive\n",
    "def rmse_eval(ratings_test, w_matrix, ratings_training):\n",
    "    # predict all the ratings for test data\n",
    "    ratings_test['prediction'] = pd.Series(np.zeros(ratings_test.shape[0]))\n",
    "    \n",
    "    for index, row_rating in ratings_test.iterrows():\n",
    "        predicted_rating = predict(row_rating['userId'], row_rating['movieId'], w_matrix, ratings_training)\n",
    "        ratings_test.loc[index, 'prediction'] = predicted_rating\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(( ratings_test['prediction']-ratings_test['rating'])**2))\n",
    "    return rmse, ratings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result on test data (RMSE) :  1.094312474949409\n"
     ]
    }
   ],
   "source": [
    "# run the evaluation\n",
    "rmse, ratings_test_predicted = rmse_eval(ratings_test, w_matrix, ratings_training)\n",
    "print('Evaluation result on test data (RMSE) : ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top K recommendations for any given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend top k movies for given userId from movies that he/she has not seen\n",
    "def recommend(userID, w_matrix, ratings, k=10):\n",
    "    \n",
    "    distinct_movies = np.unique(ratings['movieId'])\n",
    "    user_rated_movies = np.unique(ratings[ratings['userId']==userID]['movieId'])\n",
    "\n",
    "    user_unrated_movies = pd.DataFrame(columns=['movieId', 'rating'])\n",
    "\n",
    "    # predict the ratings for all movies that the user hasn't rated\n",
    "    i = 0\n",
    "    for movie in distinct_movies:\n",
    "        if movie not in user_rated_movies:\n",
    "            rating_value = predict(userID, movie, w_matrix, ratings)\n",
    "            user_unrated_movies.loc[i] = [movie, rating_value]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # select top k movies based on predicted ratings\n",
    "    recommendations = user_unrated_movies.sort_values(by=['rating'], ascending=False).head(k)\n",
    "    recommendations_list = [ [int(row['movieId']), row['rating']] for i,row in recommendations.iterrows() ]\n",
    "    return recommendations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for User:  12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[30, 2.5],\n",
       " [48825, 2.5],\n",
       " [45506, 2.5],\n",
       " [46337, 2.5],\n",
       " [46948, 2.5],\n",
       " [47200, 2.5],\n",
       " [47254, 2.5],\n",
       " [47287, 2.5],\n",
       " [47306, 2.5],\n",
       " [47330, 2.5]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 12\n",
    "print(\"Recommended movies for User: \", user)\n",
    "recommend(user, w_matrix, ratings_training, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking top k recommendation for given list of users\n",
    "def make_recommendation_for_users(users_list, ratings_training):\n",
    "    users_recommendations_df = pd.DataFrame(columns=['userId', 'recommendation'])\n",
    "    count = 0\n",
    "    for user in users_list:\n",
    "        recommendations = recommend(user, w_matrix, ratings_training, k=10)\n",
    "        users_recommendations_df.loc[count] = [user, recommendations]\n",
    "        count+=1\n",
    "    return users_recommendations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list_for_reconmmendation = list(set(ratings_training['userId']) & set(ratings_test['userId']))\n",
    "users_recommendations_df = make_recommendation_for_users(users_list_for_reconmmendation, ratings_training)\n",
    "users_recommendations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
